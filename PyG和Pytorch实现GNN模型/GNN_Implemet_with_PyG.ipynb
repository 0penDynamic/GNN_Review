{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuweigang\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "#from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyG构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "生成Graph的节点数据集，使用Cora数据集，以及torch_geometric.data.Data方法，\n",
    "需要参数如下：\n",
    "    x : torch.Tensor, 节点特征矩阵，shape为[num_nodes, num_node_features]\n",
    "    edge_index : LongTensor, Graph的连接矩阵，shape为[2, num_edges]\n",
    "    edge_attr : None, 暂不需要\n",
    "    y : Tensor, 图或节点的标签，shape任意\n",
    "    pos : Tensor, 暂不需要\n",
    "    norm : Tensor, 暂不需要\n",
    "    face : LongTensor, 暂不需要\n",
    "'''\n",
    "content_path = \"./cora/cora.content\"\n",
    "cite_path = \"./cora/cora.cites\"\n",
    "\n",
    "# 读取文本内容\n",
    "with open(content_path, \"r\") as fp:\n",
    "    contents = fp.readlines()\n",
    "with open(cite_path, \"r\") as fp:\n",
    "    cites = fp.readlines()\n",
    "\n",
    "# 边列表\n",
    "cites = list(map(lambda x: x.strip().split(\"\\t\"), cites))\n",
    "#cites = [x.strip().split(\"\\t\") for x in cites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 构建映射字典\n",
    "paper_list, feat_list, label_list = [], [], []\n",
    "for line in tqdm(contents):\n",
    "    tag, *feat, label = line.strip().split(\"\\t\")\n",
    "    paper_list.append(tag)\n",
    "    feat_list.append(np.array(list(map(lambda x: int(x), feat))))\n",
    "    label_list.append(label)\n",
    "# Paper -> Index 字典\n",
    "paper_dict = dict([(key, val) for val, key in enumerate(paper_list)])\n",
    "# Label -> Index 字典\n",
    "label_dict = dict([(key, val) for val, key in enumerate(set(label_list))])\n",
    "# Edge_index构建\n",
    "cites = np.array([[paper_dict[i[0]], paper_dict[i[1]]] for i in cites],\n",
    "                 np.int64).T                                 # (2, edge)\n",
    "#list[<start>:<stop>:<step>]\n",
    "#So, when you do a[::-1], it starts from the end towards the first taking each element. So it reverses a. This is applicable for lists/tuples as well.\n",
    "cites = np.concatenate((cites, cites[::-1, :]), axis=1)      # (2, 2*edge), 即(2, E)\n",
    "# y 构建\n",
    "y = np.array([label_dict[i] for i in label_list])\n",
    "# Input 构建\n",
    "x = torch.from_numpy(np.array(feat_list, dtype=np.float32))  # [N, Feat_Dim]\n",
    "edge_index = torch.from_numpy(cites)                         # [E, 2]\n",
    "y = torch.from_numpy(y)  # futorch.from_numpy(ndarray) → Tensor   # [N, ]\n",
    "\n",
    "# 构建Data类\n",
    "data = Data(x=x,\n",
    "            edge_index=edge_index,\n",
    "            y=y)\n",
    "# 分割数据集\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.uint8)\n",
    "data.train_mask[:data.num_nodes - 1000] = 1                  # 1700左右training\n",
    "data.val_mask = None                                         # 0valid\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.uint8)\n",
    "data.test_mask[data.num_nodes - 500:] = 1                    # 500test\n",
    "data.num_classes = len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打印数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"{}Data Info{}\".format(\"*\"*20, \"*\"*20))\n",
    "print(\"==> Is undirected graph : {}\".format(data.is_undirected()))\n",
    "print(\"==> Number of edges : {}/2={}\".format(data.num_edges, int(data.num_edges/2)))\n",
    "print(\"==> Number of nodes : {}\".format(data.num_nodes))\n",
    "print(\"==> Node feature dim : {}\".format(data.num_node_features))\n",
    "print(\"==> Number of training nodes : {}\".format(data.train_mask.sum().item()))  # fu如果tensor只有一个元素那么调用item方法的时候就是将tensor转换成python的scalars\n",
    "print(\"==> Number of testing nodes : {}\".format(data.test_mask.sum().item()))\n",
    "print(\"==> Number of classes : {}\".format(data.num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}Train Data anf Test Data Info{}\".format(\"*\"*20, \"*\"*20))\n",
    "print(\"==> Label list : \"+(\"\\n    {}\"*7).format(*[(i,j) for j,i in label_dict.items()]))\n",
    "inds, nums = np.unique(y[data.train_mask].numpy(), return_counts=True)\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "plt.bar(x=inds, height=nums, width=0.8, bottom=0, align='center')\n",
    "plt.xticks(ticks=range(7))\n",
    "plt.xlabel(xlabel=\"Label Index\")\n",
    "plt.ylabel(ylabel=\"Sample Num\")\n",
    "plt.ylim((0, 600))\n",
    "plt.title(label=\"Train Data Statics\")\n",
    "inds, nums = np.unique(y[data.test_mask].numpy(), return_counts=True)\n",
    "plt.subplot(122)\n",
    "plt.bar(x=inds, height=nums, width=0.8, bottom=0, align='center')\n",
    "plt.xticks(ticks=range(7))\n",
    "plt.xlabel(xlabel=\"Label Index\")\n",
    "plt.ylabel(ylabel=\"Sample Num\")\n",
    "plt.ylim((0, 600))\n",
    "plt.title(label=\"Test Data Statics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyG构建GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "使用官方教程上的例子，利用MessagePassing类来构建GCN层。\n",
    "初始化阶段：\n",
    "Input :\n",
    "    in_channels : (int)输入的节点特征维度\n",
    "    out_channels : (int)节点输出的特征维度\n",
    "Output :\n",
    "    None\n",
    "\n",
    "forward阶段：\n",
    "Input :\n",
    "    x : (Tensor)输入的节点特征矩阵，shape(N, in_channels)\n",
    "    edge_index : (LongTensor)输入的边矩阵，shape(2, E)\n",
    "Output :\n",
    "    out : (Tensor)输出层的节点logits，shape(N, num_class)\n",
    "'''\n",
    "\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        #python中的super( test, self).__init__()\n",
    "        #首先找到test的父类（比如是类A），然后把类test的对象self转换为类A的对象，然后“被转换”的类A对象调用自己的__init__函数\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)  # (N, in_channels) -> (N, out_channels)\n",
    "\n",
    "        # Step 3-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, size=None, x=x, n_nodes=x.size(0))\n",
    "\n",
    "    def message(self, x_j, edge_index, n_nodes):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 3: Normalize node features.\n",
    "        row, col = edge_index  # [E,], [E,] fu row,col 都是 torch.tensor类型\n",
    "        deg = degree(row, n_nodes, dtype=x_j.dtype)  # [N, ] fu tensor，一维的\n",
    "        deg_inv_sqrt = deg.pow(-0.5)   # [N, ]\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]  # [E, ] fu  deg_inv_sqrt[row]这种索引切片方式在numpy中是无法使用的，只能在torch.tensor中使用\n",
    "\n",
    "        return norm.view(-1, 1) * x_j  # fu norm.view相当于reshape，这里一维norm变二维norm(E,1)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out\n",
    "\n",
    "# from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建模型，使用两层GCN，第一层GCN使得节点矩阵\n",
    "        (N, in_channel) -> (N, 16)\n",
    "第二层GCN使得节点矩阵\n",
    "        (N, 16) -> (N, num_class)\n",
    "激活函数使用relu函数，网络最后对节点的各类别score使用softmax归一化，\n",
    "返回归一化后的Tensor。\n",
    "'''\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, feat_dim, num_class):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(feat_dim, 16)#fu 这里的参数是传递给GCNConv中的__init__函数\n",
    "        self.conv2 = GCNConv(16, num_class)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)#fu认为这时括号中的参数就会传递给GCNConv类中的forward()函数，返回值也是由forward()函数提供的\n",
    "        x = F.relu(x)  # fu认为激活函数放在这里，而不是放在GCNConv类中的update函数中，原因是：下一层conv2的激活函数和这一层conv1的激活函数是不同的。\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "开始训练模型\n",
    "'''\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(feat_dim=data.num_node_features, num_class=7).to(device)         # Initialize model\n",
    "data = data.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) # Initialize optimizer and training params\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
    "    dict(params=model.conv2.parameters(), weight_decay=0)\n",
    "], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Get output\n",
    "    out = model(data)#fu认为这时括号中的参数就会传递给Net类中的forward()函数，返回值也是由forward()函数提供的\n",
    "\n",
    "    # Get loss\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    _, pred = out.max(dim=1)  # fu 取出网络的预测值\n",
    "\n",
    "    # Get predictions and calculate training accuracy\n",
    "    correct = float(torch.masked_select(pred, data.train_mask.byte()).eq(torch.masked_select(data.y, data.train_mask.byte())).sum().item())\n",
    "    acc = correct / data.train_mask.sum().item()\n",
    "    print('[Epoch {}/200] Loss {:.4f}, train acc {:.4f}'.format(epoch, loss.cpu().detach().data.item(), acc))\n",
    "\n",
    "    # Backward\n",
    "    loss.backward()  # fu 根据计算出来的损失值，进行梯度反向传播，计算梯度\n",
    "    optimizer.step()  # fu 根据梯度调整每个网络层的权重参数\n",
    "\n",
    "    # Evaluation on test data every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model.eval()\n",
    "        _, pred = model(data).max(dim=1)\n",
    "        correct = float(pred[data.test_mask.byte()].eq(data.y[data.test_mask.byte()]).sum().item())\n",
    "        acc = correct / data.test_mask.sum().item()\n",
    "        print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf37jupyter",
   "language": "python",
   "name": "tf37jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

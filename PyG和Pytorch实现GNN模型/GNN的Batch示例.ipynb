{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN的Batch示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题简介**：由于GNN处理的数据通常来说是不规则、格式不统一的图(graph)，因此，如何将数据进行批处理并输入到神经网络中进行训练是一个比较常见的问题，该代码使用`对角邻接矩阵`的方式来实现批处理问题(受到了PyG框架的启发)。该代码的数据集使用人工生成的图分类数据集，并使用Pytorch框架进行实现数据载入、模型构建、训练、评估等流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务定义和数据集生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "子图匹配分类：给定一个子图(subgraph)$g$以及图(graph)的数据集$\\mathcal{G}=\\{G_1,G_2,...,G_n\\}$，对应的标签为$\\mathcal{Y}=\\{y_1,y_2,...,y_n\\}$，对于任意的图(graph)$G_i$及其标签$y_i$，有：\n",
    "$$\n",
    "\\begin{equation}\n",
    "y_i=\\left\\{\n",
    "\\begin{aligned}\n",
    "1 & \\text{ }G_i包含子图g \\\\\n",
    "0 & \\text{ }G_i不包含子图g \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图(graph)都可以定义为$m$个节点的集合$\\mathcal{N}=\\{v_1,v_2,...,v_m\\}$和$n$条边的集合$\\mathcal{E}=\\{e_1,e_2,...,e_n\\}$，其中，边的数据结构为两个节点的元组，即$(v_i,v_j)$。现设定数据集： \n",
    "+ 有26种节点：A,B,C,...,Z。每一种节点都有特定的特征向量，比如one-hot。\n",
    "+ 图(graph)由不定数量的上述类型节点和不定数量连接的边构成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for dataset generation.\n",
    "\"\"\"\n",
    "import string\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving node dict...\n",
      "Successfully saving dict!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generating nodes dict.\n",
    "\"\"\"\n",
    "node_types = list(string.ascii_uppercase)\n",
    "nodes_dict = dict([(k, v) for v, k in enumerate(node_types)])\n",
    "nodes_dict_path = \"./data/nodes_dict.json\"\n",
    "\n",
    "print(\"Saving node dict...\")\n",
    "with open(nodes_dict_path, \"w\") as fp:\n",
    "    json.dump({\n",
    "        \"itos\" : node_types,\n",
    "        \"stoi\" : nodes_dict\n",
    "    }, fp)\n",
    "print(\"Successfully saving dict!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 graphs have been generated!\n",
      "2000 graphs have been generated!\n",
      "2000 graphs have been generated!\n",
      "3000 graphs have been generated!\n",
      "4000 graphs have been generated!\n",
      "5000 graphs have been generated!\n",
      "6000 graphs have been generated!\n",
      "7000 graphs have been generated!\n",
      "8000 graphs have been generated!\n",
      "9000 graphs have been generated!\n",
      "10000 graphs have been generated!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Show graph.\n",
    "Input : \n",
    "    g : tuple(list, list)\n",
    "\"\"\"\n",
    "def show_graph(g):\n",
    "    labels = dict([(k,v) for k, v in enumerate(g[0])])\n",
    "    nodes = range(len(g[0]))\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(g[1])\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos)\n",
    "    nx.draw_networkx_labels(G, pos, labels)\n",
    "\n",
    "subgraph = ([\"A\", \"A\", \"B\", \"C\"], \n",
    "            [(0, 1),\n",
    "             (0, 2),\n",
    "             (1, 2),\n",
    "             (2, 3)])\n",
    "min_nodes_num = 5\n",
    "max_nodes_num = 50\n",
    "graph_num = 10000\n",
    "\n",
    "\"\"\"\n",
    "Generating graph dataset. There are three steps:\n",
    "Step1 : Randomly choose number of nodes(N).\n",
    "Step2 : Generate random graph with edge number ranging from N-1 to N * (N - 1) / 2.\n",
    "Step3 : Remove unconnected graph.\n",
    "Step4 : Add subgraph to some graphs.\n",
    "\"\"\"\n",
    "N = 0\n",
    "graphs = []\n",
    "random.seed(0)\n",
    "while N < graph_num:\n",
    "    node_num = random.randint(min_nodes_num, max_nodes_num)\n",
    "    edge_num = random.randint(node_num-1, node_num * (node_num - 1) / 2)\n",
    "    G = nx.random_graphs.dense_gnm_random_graph(node_num, edge_num)\n",
    "    if nx.connected.is_connected(G):\n",
    "        graphs.append(G)\n",
    "        N += 1\n",
    "        if N % 1000 == 0:\n",
    "            print(\"{} graphs have been generated!\".format(N))\n",
    "\n",
    "\"\"\"\n",
    "Transform nx.Graph into our graph type.\n",
    "\"\"\"\n",
    "def transform_nx_graph(g):\n",
    "    nodes = random.choices(population=node_types, k=len(g.nodes))\n",
    "    edges = list(g.edges)\n",
    "    \n",
    "    return (nodes, edges)\n",
    "\n",
    "\"\"\"\n",
    "Merge subgraph into graph.\n",
    "\"\"\"\n",
    "def merge_subgraph_into_graph(g, sg):\n",
    "    g_node_num = len(g[0])\n",
    "    sg_node_num = len(sg[0])\n",
    "    \n",
    "    merge_edges = [(s+g_node_num, d+g_node_num) for s, d in sg[1]]\n",
    "    \n",
    "    g_range = range(g_node_num)\n",
    "    sg_range = range(g_node_num, g_node_num+sg_node_num)\n",
    "    new_edges_num = random.randint(1, g_node_num)\n",
    "    src_list = random.choices(population=g_range, k=new_edges_num)\n",
    "    dst_list = random.choices(population=sg_range, k=new_edges_num)\n",
    "    new_edges = [(s, d) for s, d in zip(src_list, dst_list)]\n",
    "    new_edges = list(set(new_edges))\n",
    "    \n",
    "    merge_graph = (g[0]+sg[0],\n",
    "                   g[1]+merge_edges+new_edges)\n",
    "    \n",
    "    return merge_graph\n",
    "\n",
    "graphs = [transform_nx_graph(g) for g in graphs]\n",
    "graphs_with_sg = [(merge_subgraph_into_graph(g, subgraph), 1) for g in graphs[:len(graphs)//2]]\n",
    "graphs_without_sg = [(g, 0) for g in graphs[len(graphs)//2:]]\n",
    "graphs = graphs_with_sg + graphs_without_sg\n",
    "random.shuffle(graphs)\n",
    "\n",
    "print(\"Saving dataset!\")\n",
    "dataset_path = \"./data/dataset.json\"\n",
    "with open(dataset_path, \"w\") as fp:\n",
    "    json.dump({\n",
    "        \"time\" : time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "        \"subgraph\" : subgraph,\n",
    "        \"graphs\" : graphs,\n",
    "        \"min_nodes_num\" : min_nodes_num,\n",
    "        \"max_nodes_num\" : max_nodes_num,\n",
    "        \"graphs_num\" : graph_num\n",
    "    }, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
